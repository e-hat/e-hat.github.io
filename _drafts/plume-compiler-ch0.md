---
title: Overview
slug: plume-compiler-ch0
series: true
chapter: 0
category: Writing Plume's Compiler
---
## Introduction
In this series I'll be going over how I implemented each step of the compilation
process for my custom programming language, Plume, which targets x86-64 assembly. 
Plume is still under heavy 
development as I write this, but I thought it would be a nice chance to relax 
and meditate on some of my decisions. 

This post will go over the general stages of the compiler I am writing, such as 
their inputs and outputs and what invariants they establish. There's a good chance 
that other posts in the series will require working knowledge of Haskell/functional 
programming, but I think this chapter will be a high level overview that 
doesn't go into that level of detail. 

For the other posts in the series that need FP knowledge, it will be helpful to have at least read 
[LYAH](http://learnyouahaskell.com/).

The source code for the compiler lives [here](https://github.com/e-hat/plume) in
case you want to follow along, as I may be citing some source files.

*Disclaimer: Both this article and I are works in progress. I will improve these articles as I learn 
more, but don't take them as pure fact. They simply are the steps I figured out 
to writing my own simple one.*

## Overview of Stages

My compiler is broken into the following stages, each of which I will explain 
in detail:
```
Lexer --> Parser --> Scope Resolver 
--> Type checker --> Bytecode Generator 
--> Register allocater --> x86-64 Translator
```

Other compilers may have some other stages, like stages dealing with syntactic sugar
and built-in assemblers/linkers, but not mine. Also I don't do much at the moment 
about any IR optimizations, but I plan to at some point in the future. Or maybe I wont! :)

### Lexer 
The lexer for Plume (that lives in `Lexer.hs`) is mainly handled by Parsec, which 
is a parser-generator library for Haskell. Lexing/parsing was not a huge interest of mine for this project,
so I decided to rely on a 3rd party library to do the heavy lifting, although I did 
work quite a bit on the syntactical structure of Plume. Lexing involves breaking the source file 
into individual "tokens," based on the keywords and such of the language. In this case,
lexing allows Plume code to have arbitrary amounts of whitespace, much like C++
or Java. These tokens are pretty much the words of the programming language.

Here's an example of how a line of Plume gets "lexed":

```python
Int n := 5
```
will be translated into something like this
```haskell
["Int", "n", ":=", "5"]
```
The following would be lexed in the exact same way:
```python
Int        
    n   :=    
5
```
Spoiler: I don't find lexing nearly as interesting as the rest of the compiler. 
Let's move on.

### Parser 
The parser takes in a stream of tokens and outputs an Abstract Syntax Tree (AST)
according to the grammar of the language.

This is pretty similar to how spoken languages work, albeit with computers the 
rules are more precise. In english, sentences are constructed in certain patterns,
called a grammar, so that meaning can be derived from them. There is a grammatical 
standard that is followed so that each sentence can be interpreted unambiguously 
and if the standard is not followed, the sentence just does not make sense.

*Note: I am not a grammar expert, so my grammatical analogies may not be perfectly 
correct according to the official definitions of grammar, syntax, etc.*

In the context of programming languages, each type of statement in the language 
has a grammar associated with it. The lexer provides the parsing stage with the 
words in the clause the programmer is writing, and the parser classifies which 
denomination of clause it is. If the words do not match any valid clause, then the programmer 
gets a syntax error, which is the compiler saying "Um...exuse me?"

Anyway, the AST is the output of the parsing step and it contains the "structure" of the 
program. Take the following snippet for example, which we've seen before:
```python
Int n := 5
```
The corresponding AST for this line, as generated by the Plume compiler, is `result` in
this snippet:
```haskell
data ASTNode = Let Type Identifier Expr | ...
data Expr = IntLiteral Integer | ...

result :: ASTNode 
result = Let "Int" "a" (IntLiteral 5)
```
This can be used for the later steps of the Plume compilation process. Also, since 
it's a tree structure, it's important to think of this recursively. An `Expr` could be 
build from multiple `ASTNode`'s and vice-versa.

### Semantics
Now that we have the program in a manageable form, we can starting providing 
helpful errors that attempt to interpret the meaning of the program, that don't 
just say that the program is written incorrectly. It's almost like taking an english 
sentence that is written with correct grammar and making sure it actually says something 
logical. For instance, "the dog flew the plane" has correct grammar, but 
<u>dogs cannot fly planes</u>.

There are two parts to this process in the Plume compiler, but they may be more 
extensive or there may be other steps entirely in other languages.

#### Scope Resolution
In the Plume compiler, this refers to making sure that variables are *in scope* 
before their values are used, and that certain naming conflicts do not occur.

This requires building a *symbol table* for each node, which keeps track of which 
variables are in scope for that node to use. If any variables are found that aren't 
in the symbol table, an error gets thrown.

Also, type information about each variable and function is stored in the symbol table, 
which is used in the following step.

#### Typechecking
Each time the programmer declares the type of something in their Plume code, the 
information is used to see whether the types in the program are what the programmer 
says they are. For example, the following Plume code would not compile due to a 
type error:
```python
Int a := "Hello" # clearly a Int assigned to a String
```
The resulting error:
```
Error: could not unify type `Int` with type `String`
```
The compiler computes the type of `"Hello"` and compares with `Int`. If they 
don't match, it's an error. This happens for Let declarations as we see above, 
the result expressions (return values)
of the functions and the types of the parameters for a function call as well. 

There are also some interesting quirks to this process due to the properties of 
the Plume programming language. 

### Bytecode Generation
Ok, we have done some of the work to make sure the programmer doesn't have annoying errors
although we can't do all of their work for them (\*cough\* Halting Problem \*cough\*). 
Now, we can move forward with actually 
generating an chunk of x86-64 code for the computer to execute.

The first step of this is to generate instructions that are "simpler" than Plume 
code, but "more complex" than x86-64 assembly (I use quotes because x86-64 can be 
annoyingly complex). This form of the program is called "bytecode" in the Plume compiler.

It serves as an intermediate form between the pure Plume code and the final assembly 
output, since it would be tons of work the go straight to x86-64 from the AST. 
Also, some optimizations can be done here to improve the performance.

The instructions use an infinite number of "virtual" registers, but they still 
use instructions like `Add 5, $1` and `Move 22, $8`, where `$n` corresponds to 
virtual register `n`. 

This had some interesting bugs that I'd like to write about someday, maybe this summer.

### Register allocation
This is an important step for both improving performance for the compiler and 
getting closer to outputting bonafide x86-64. It replaces the bytecode that uses 
an unlimited number of virtual registers with bytecode that only uses the 
number of physical registers specified by the machine.

This improves performance because, if it is done effectively, lots of the memory 
used throughout the program can be stored in registers that are ultra fast. 
If a piece of bytecode simply cannot store all of its data in physical registers, 
they will be "spilled" onto the stack, which is a bit slower to access. 

### Final translation
Finally, we have bytecode that is ready to be translated to x86-64. There are some 
annoying parts to this, but the bytecode used in the Plume compiler is quite close 
to x86-64 so some of the more annoying parts have already been worked out.

This gets emitted, then assembled and  linked by the user, *then* they can run their 
Plume program!

## Outro
This was a lot of topics. It might take me a while to get through this series, 
especially depending on how much detail I go into in each chapter. I'll just 
add chapters when I feel like it and see how far I get. Also, I think I'm going 
to start doing some writeups of bugs I come across, since they can be kind of 
interesting and annoying. Next up will be chapter 1 where I talk about Parsing and 
Lexing. 

